<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>LLM on Inductive Bias</title><link>https://blog.isabel-drost.de/tags/LLM/</link><description>Recent content in LLM on Inductive Bias</description><generator>Hugo -- gohugo.io</generator><lastBuildDate>Sun, 01 Jun 2025 16:07:28 +0100</lastBuildDate><atom:link href="https://blog.isabel-drost.de/tags/LLM/index.xml" rel="self" type="application/rss+xml"/><item><title>Playing with LLMs locally</title><link>https://blog.isabel-drost.de/llm-tool-locally/</link><pubDate>Sun, 01 Jun 2025 16:07:28 +0100</pubDate><guid>https://blog.isabel-drost.de/llm-tool-locally/</guid><description>Playing with LLMs locally # After a talk by Nick Burch at Berlin Buzzwords I finally got started playing with LLMs locally. The easiest way to get started for me: llm tool by Simon Willison :)
Backstory # Back when it came out in winter 2022 I started playing around with ChatGPT - mostly to generate texts from individual terms given as what teachers in German primary schools call &amp;ldquo;learning words&amp;rdquo; - usually they are handed out for pupils to get prepared for a dictation (written to check spelling skills): It&amp;rsquo;s a lot more fun to prepare for theses tests with fun texts than with mere lists of words :) Back then the results were impressive - but also frightning given the implications for ease of generating mis-information, fake social media profiles, spamming search indeces and more.</description></item></channel></rss>